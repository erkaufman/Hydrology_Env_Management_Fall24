---
title: "Appendix"
author: "Emma Kaufman, Mark Lamendola, and Sarah Sussman"
date: "2024-10-02"
output: pdf_document
---

```{r message=FALSE, warning=FALSE, include=FALSE}
# load packages
library(readxl)
library(dplyr)
library(tidyverse)
library(zoo)
library(ggplot2)

# read in raw data
Greensboro_raw <- read_excel("Data/Hydrology_memo_2.xlsx", 
    sheet = "Greensboro_daily_precip_1980-pr", 
    col_types = c("date", "text", "numeric", 
        "numeric", "numeric"), na = "NaN")

Boone_raw <- read_excel("Data/Hydrology_memo_2.xlsx", 
    sheet = "Boone_daily_precip_1980-present", 
    col_types = c("date", "text", "numeric", 
        "numeric", "numeric"), na = "NaN")

Greenville_raw <- read_excel("Data/Hydrology_memo_2.xlsx", 
    sheet = "Greenville_daily_precip_1980-pr", 
    col_types = c("date", "text", "numeric", 
        "numeric", "numeric"), na = "NaN")

Boone_raw$`Area Weighted Mean Precipitation (mm per day)` <- 
  as.numeric(Boone_raw$`Area Weighted Mean Precipitation (mm per day)`)

Greensboro_raw$`Area Weighted Mean Precipitation (mm per day)` <- 
  as.numeric(Greensboro_raw$`Area Weighted Mean Precipitation (mm per day)`)

Greenville_raw$`Area Weighted Mean Precipitation (mm per day)` <- 
  as.numeric(Greenville_raw$`Area Weighted Mean Precipitation (mm per day)`)
```

### Data

The daily area weighted mean precipitation data used for these analyses came from USGS gauging stations in Boone, Greensboro, and Greenville. The HUC codes for each station are as follows:

-   Boone HUC 050500010201
-   Greensboro HUC 030300020105
-   Greenville 030201030403

We used these data to analyze whether precipitation characteristics have changed for the different college campuses located in each of these cities since the last major investment in infrastructure that wrapped up in 1999. 

We began our analysis by preparing the data to analyze different storm event durations, focusing on 24-hr and 72-hr storm events. To get estimates for 72-hr storm events we took a rolling sum across a 3 day window to get an estimated 72-hour storm event for each day. For 24-hr storm events we took a moving average of 24-hr data over a 7-day window to ensure each event being analyzed was statistically different from the others, which is an assumption of the Weibull recurrence interval calculation.

For the 24-hour data we then found monthly maximum 24 hour events for each month in each year of available data. The maximum 24-hour storm event for each month from 1980-2016 was then used to calculate recurrence intervals for 24-hour storm events. 

```{r message=FALSE, warning=FALSE, include=FALSE}
Boone_rolling_sum <- Boone_raw %>%
  # Remove NAs for leap year issues
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>% 
  mutate(
    # Rolling sums
    rolling_48hr = rollapply(`Area Weighted Mean Precipitation (mm per day)`, 
                             width = 2, FUN = sum, fill = NA, align = 'right'),
    rolling_72hr = rollapply(`Area Weighted Mean Precipitation (mm per day)`,
                             width = 3, FUN = sum, fill = NA, align = 'right')
  )

Greensboro_rolling_sum <- Greensboro_raw %>%
  # Remove NAs for leap year issues
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>% 
  mutate(
    # Rolling sums
    rolling_48hr = rollapply(`Area Weighted Mean Precipitation (mm per day)`, 
                             width = 2, FUN = sum, fill = NA, align = 'right'),
    rolling_72hr = rollapply(`Area Weighted Mean Precipitation (mm per day)`, 
                             width = 3, FUN = sum, fill = NA, align = 'right')
  )

Greenville_rolling_sum <- Greenville_raw %>% 
  # Remove NAs for leap year issues
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>% 
  mutate(
    # Rolling sums
    rolling_48hr = rollapply(`Area Weighted Mean Precipitation (mm per day)`,
                             width = 2, FUN = sum, fill = NA, align = 'right'),
    rolling_72hr = rollapply(`Area Weighted Mean Precipitation (mm per day)`, 
                             width = 3, FUN = sum, fill = NA, align = 'right')
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Boone
# Take a moving average over a 7 day window
Boone_24hr <- Boone_raw %>%
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>%
  mutate(weekly_avg_24hr_precip = rollmean(
    `Area Weighted Mean Precipitation (mm per day)`, 
    k = 7, #weekly rolling average
    fill = NA, 
    align = "right"))

# find monthly avg and max for 24 hour events
Boone_24hr_monthlyavg <- Boone_24hr %>% 
  slice(-1, -2, -3, -4, -5, -6) %>% #skip first three rows bc NA
  group_by(year,month) %>% 
  summarize(max_24_mm = max(weekly_avg_24hr_precip),
            avg_24_mm = mean(weekly_avg_24hr_precip)) %>% 
  mutate(Timeframe = as.factor(ifelse(year>=2000,"2000-2016","1980-1999")))


# Greensboro
# Take a moving average over a 7 day window
Greensboro_24hr <- Greensboro_raw %>%
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>%
  mutate(weekly_avg_24hr_precip = rollmean(
    `Area Weighted Mean Precipitation (mm per day)`,
    k = 7, 
    fill = NA, 
    align = "right"))

#find monthly avg and max for 24 hour events
Greensboro_24hr_monthlyavg <- Greensboro_24hr %>% 
  slice(-1, -2, -3, -4, -5, -6) %>% #skip first three rows bc NA
  group_by(year,month) %>% 
  summarize(max_24_mm = max(weekly_avg_24hr_precip),
            avg_24_mm = mean(weekly_avg_24hr_precip)) %>% 
  mutate(Timeframe = as.factor(ifelse(year>=2000,"2000-2016","1980-1999")))


# Greenville
# moving average over 7 day window
Greenville_24hr <- Greenville_raw %>%
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>%
  mutate(weekly_avg_24hr_precip = rollmean(
    `Area Weighted Mean Precipitation (mm per day)`, 
    k = 7, 
    fill = NA, 
    align = "right"))

# find monthly avg and max for 24 hour events
Greenville_24hr_monthlyavg <- Greenville_24hr %>% 
  slice(-1, -2, -3, -4, -5, -6) %>% #skip first three rows bc NA
  group_by(year,month) %>% 
  summarize(max_24_mm = max(weekly_avg_24hr_precip),
            avg_24_mm = mean(weekly_avg_24hr_precip)) %>% 
  mutate(Timeframe = as.factor(ifelse(year>=2000,"2000-2016","1980-1999")))


```
We calculated both the Weibull and Hazen recurrence intervals for Boone, Greensboro, and Greenville's monthly maximum 24-hour and 72-hour storm events from 1980-1999 and from 2000-2016. Recurrence intervals using each method differed due to Weibull being more conservative (assigning higher return periods for more extreme events), and Hazen being less conservative (assigning a smoother distribution of recurrence intervals). Due to the large sample size and wanting to have conservative estimates due to the application of using these return periods being used for flood mitigation, we moved forward with using Weibull return periods for our decision making process.

Rolling sum for each 72hr period, then got the average total precipitation in a 72hr period per month, and max total 72 hour precip per month

```{r message=FALSE, warning=FALSE, include=FALSE}
# Rank events and calculate return periods
# Boone
Boone_recurrence_24hr <- Boone_24hr_monthlyavg %>% 
  group_by(Timeframe) %>% 
  arrange(desc(max_24_mm)) %>% 
  mutate(
    Rank = rank(-max_24_mm),
    weibull_return_24hr = ((n()+1)/Rank),
    weibull_return_24_year = weibull_return_24hr/12,
    weibull_percent_likelihood=(1/weibull_return_24_year)*100*12,
    weibull_percent_likelihood_yr=(1/weibull_return_24_year)*100,
    hazen_percent_likelihood = 100*(2*Rank-1)/(2*n()),
    hazen_percent_likelihood_yr = 12*100*(2*Rank-1)/(2*n()),
    hazen_return_24hr = 100/hazen_percent_likelihood,
    hazen_return_24hr_year = hazen_return_24hr/12,
    log_prob_occurence_hazen = log(hazen_percent_likelihood_yr),
    log_prob_occurence_weibull = log(weibull_percent_likelihood_yr)
  )

# Greensboro
Greensboro_recurrence_24hr <- Greensboro_24hr_monthlyavg %>% 
  group_by(Timeframe) %>% 
  arrange(desc(max_24_mm)) %>% 
  mutate(
    Rank = rank(-max_24_mm),
    weibull_return_24hr = ((n()+1)/Rank),
    weibull_return_24_year = weibull_return_24hr/12,
    weibull_percent_likelihood=(1/weibull_return_24_year)*100*12,
    weibull_percent_likelihood_yr=(1/weibull_return_24_year)*100,
    hazen_percent_likelihood = 100*(2*Rank-1)/(2*n()),
    hazen_percent_likelihood_yr = 12*100*(2*Rank-1)/(2*n()),
    hazen_return_24hr = 100/hazen_percent_likelihood,
    hazen_return_24hr_year = hazen_return_24hr/12,
    log_prob_occurence_hazen = log(hazen_percent_likelihood_yr),
    log_prob_occurence_weibull = log(weibull_percent_likelihood_yr)
  )

# Greenville
Greenville_recurrence_24hr <- Greenville_24hr_monthlyavg %>% 
  group_by(Timeframe) %>% 
  arrange(desc(max_24_mm)) %>% 
  mutate(
    Rank = rank(-max_24_mm),
    weibull_return_24hr = ((n()+1)/Rank),
    weibull_return_24_year = weibull_return_24hr/12,
    weibull_percent_likelihood=(1/weibull_return_24_year)*100*12,
    weibull_percent_likelihood_yr=(1/weibull_return_24_year)*100,
    hazen_percent_likelihood = 100*(2*Rank-1)/(2*n()),
    hazen_percent_likelihood_yr = 12*100*(2*Rank-1)/(2*n()),
    hazen_return_24hr = 100/hazen_percent_likelihood,
    hazen_return_24hr_year = hazen_return_24hr/12,
    log_prob_occurence_hazen = log(hazen_percent_likelihood_yr),
    log_prob_occurence_weibull = log(weibull_percent_likelihood_yr)
  )

```


```{r}
# Boone
#Take the maximum 72hr event for each month across all years
Boone_72hr_monthlyavg <- Boone_rolling_sum %>% 
  slice(-1, -2) %>% #skip first two rows bc NA
  group_by(year,month) %>% 
  summarize(max_72hr_mm = max(rolling_72hr),
            avg_72hr_mm = mean(rolling_72hr)) %>% 
  mutate(Timeframe = as.factor(ifelse(year>=2000,"2000-2016","1980-1999")))

#calculate recurrence intervals for each monthly maximum event across all years
Boone_72hr_recurrence<- Boone_72hr_monthlyavg %>% 
  group_by(Timeframe) %>% 
  arrange(desc(max_72hr_mm)) %>% 
  mutate(
    Rank = rank(-max_72hr_mm),
    weibull_return_72hr = ((n()+1)/Rank),
    weibull_return_72_year = weibull_return_72hr/12,
    weibull_percent_likelihood=(1/weibull_return_72_year)*100*12,
    weibull_percent_likelihood_yr=(1/weibull_return_72_year)*100,
    hazen_percent_likelihood = 100*(2*Rank-1)/(2*n()),
    hazen_percent_likelihood_yr = 12*100*(2*Rank-1)/(2*n()),
    hazen_return_72hr = 100/hazen_percent_likelihood,
    hazen_return_72hr_year = hazen_return_72hr/12,
    log_prob_occurence_hazen = log(hazen_percent_likelihood_yr),
    log_prob_occurence_weibull = log(weibull_percent_likelihood_yr)
  )

# Greensboro
Greensboro_72hr_monthlyavg <- Greensboro_rolling_sum %>% 
  slice(-1, -2) %>% #skip first two rows bc NA
  group_by(year,month) %>% 
  summarize(max_72hr_mm = max(rolling_72hr),
            avg_72hr_mm = mean(rolling_72hr)) %>% 
  mutate(Timeframe = as.factor(ifelse(year>=2000,"2000-2016","1980-1999")))

#calculate recurrence intervals for each monthly maximum event across all years
Greensboro_72hr_recurrence<- Greensboro_72hr_monthlyavg %>% 
  group_by(Timeframe) %>% 
  arrange(desc(max_72hr_mm)) %>% 
  mutate(
    Rank = rank(-max_72hr_mm),
    weibull_return_72hr = ((n()+1)/Rank),
    weibull_return_72_year = weibull_return_72hr/12,
    weibull_percent_likelihood=(1/weibull_return_72_year)*100*12,
    weibull_percent_likelihood_yr=(1/weibull_return_72_year)*100,
    hazen_percent_likelihood = 100*(2*Rank-1)/(2*n()),
    hazen_percent_likelihood_yr = 12*100*(2*Rank-1)/(2*n()),
    hazen_return_72hr = 100/hazen_percent_likelihood,
    hazen_return_72hr_year = hazen_return_72hr/12,
    log_prob_occurence_hazen = log(hazen_percent_likelihood_yr),
    log_prob_occurence_weibull = log(weibull_percent_likelihood_yr)
  )

# Greenville
Greenville_72hr_monthlyavg <- Greenville_rolling_sum %>% 
  slice(-1, -2) %>% #skip first two rows bc NA
  group_by(year,month) %>% 
  summarize(max_72hr_mm = max(rolling_72hr),
            avg_72hr_mm = mean(rolling_72hr)) %>% 
  mutate(Timeframe = as.factor(ifelse(year>=2000,"2000-2016","1980-1999")))

#calculate recurrence intervals for each monthly maximum event across all years
Greenville_72hr_recurrence<- Greenville_72hr_monthlyavg %>% 
  group_by(Timeframe) %>% 
  arrange(desc(max_72hr_mm)) %>% 
  mutate(
    Rank = rank(-max_72hr_mm),
    weibull_return_72hr = ((n()+1)/Rank),
    weibull_return_72_year = weibull_return_72hr/12,
    weibull_percent_likelihood=(1/weibull_return_72_year)*100*12,
    weibull_percent_likelihood_yr=(1/weibull_return_72_year)*100,
    hazen_percent_likelihood = 100*(2*Rank-1)/(2*n()),
    hazen_percent_likelihood_yr = 12*100*(2*Rank-1)/(2*n()),
    hazen_return_72hr = 100/hazen_percent_likelihood,
    hazen_return_72hr_year = hazen_return_72hr/12,
    log_prob_occurence_hazen = log(hazen_percent_likelihood_yr),
    log_prob_occurence_weibull = log(weibull_percent_likelihood_yr)
  )
```

After calculating return intervals for each 24-hour and 72-hour storm event in each time frame of interest (pre- and post-2000) we plotted the difference in return periods from 1980-1999 and from 2000-2016 for each city. 

Since 1980-1999, events of the same likelihood have become more intense. For example, in Boone, a 1 inch 24-hour event from 1980-1999 had a 37.5% chance of occurring. More recent data (2000-2016) shows that the same likelihood event would be associated with around a 1.25 in 24 hour event. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Boone

Boone_24hr_plot_hazen <- Boone_recurrence_24hr %>%
  ggplot(aes(x = log_prob_occurence_hazen, 
             y = max_24_mm, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%) (Hazen)", 
       y = "Maximum 24-Hour Precipitation (mm)", 
       title = "Boone Monthly maximum 24-Hour Precipitation vs Probability of Occurrence (Hazen)") +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_reverse(  # Keep the x-axis reversed
    labels = function(x) round(exp(x), 2)  # Convert log values back to probabilities for labels
  )

Boone_24hr_plot_weibull <- Boone_recurrence_24hr %>%
  ggplot(aes(x = weibull_percent_likelihood_yr, 
             y = max_24_mm/25.4, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%)", 
       y = "Maximum 24-Hour Precipitation (in)", 
       title = "Monthly maximum 24-hour storm recurrence intervals",
       subtitle = "Boone, NC",
       color = NULL) +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_log10(
    trans = "reverse",  # Reverse the log10 x-axis
    limits = c(100, 1),  # Set the x-axis limits from 100 to 1
    breaks = c(100, 50, 25, 10, 5, 1),  # Custom breaks
    labels = c(100, 50, 25, 10, 5, 1)  # Custom labels for breaks
  )+ 
  theme(legend.position = "top")

Boone_24hr_plot_weibull
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
Greensboro_24hr_plot_weibull <- Greensboro_recurrence_24hr %>%
  ggplot(aes(x = weibull_percent_likelihood_yr, 
             y = max_24_mm/25.4, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%)", 
       y = "Maximum 24-Hour Precipitation (in)", 
       title = "Monthly maximum 24-hour storm recurrence intervals",
       subtitle = "Greensboro, NC",
       color = NULL) +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_log10(
    trans = "reverse",  # Reverse the log10 x-axis
    limits = c(100, 1),  # Set the x-axis limits from 100 to 1
    breaks = c(100, 50, 25, 10, 5, 1),  # Custom breaks
    labels = c(100, 50, 25, 10, 5, 1)  # Custom labels for breaks
  )+ 
  theme(legend.position = "top")


Greensboro_24hr_plot_weibull
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
Greenville_24hr_plot_weibull <- Greenville_recurrence_24hr %>%
  ggplot(aes(x = weibull_percent_likelihood_yr, 
             y = max_24_mm/25.4, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%)", 
       y = "Maximum 24-Hour Precipitation (in)", 
       title = "Monthly maximum 24-hour storm recurrence intervals",
       subtitle = "Greenville, NC",
       color = NULL) +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_log10(
    trans = "reverse",  # Reverse the log10 x-axis
    limits = c(100, 1),  # Set the x-axis limits from 100 to 1
    breaks = c(100, 50, 25, 10, 5, 1),  # Custom breaks
    labels = c(100, 50, 25, 10, 5, 1)  # Custom labels for breaks
  )+ 
  theme(legend.position = "top")


Greenville_24hr_plot_weibull
```


Need to extract the precipitation depths for 10, 25, 50, and 100 year floods for each time period (for this 24 hour event). Fit a line of best fit to the probability distribution to interpolate for flood events that aren't observed.

```{r}
#weibull
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Boone_recurrence_24hr$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Boone_recurrence_24hr %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_24_mm ~ log_prob_occurence_weibull, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_weibull = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Predicted_Precipitation_24hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

Now we need to compare the monthly average from 2000-2016 maximum monthly 24-hr rain event. See which months exceed a 25 year flood from 1980-1999.

```{r}
prob_4_percent_value <- final_results %>%
  filter(Timeframe == '1980-1999', Probability == 4) %>%
  pull(Predicted_Precipitation_24hr_mm)

boone_monthly_new_data <- Boone_24hr_monthlyavg %>% 
  filter(Timeframe=='2000-2016') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_24_mm),
            max=max(max_24_mm),
            exceed_count = sum(max_24_mm > prob_4_percent_value)) %>% 
  
  ungroup()

boone_monthly_old_data <-  Boone_24hr_monthlyavg %>% 
  filter(Timeframe=='1980-1999') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_24_mm),
            max=max(max_24_mm)) %>% 
  ungroup()
```

Greensboro 24-hr events


```{r}
#weibull
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Greensboro_recurrence_24hr$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Greensboro_recurrence_24hr %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_24_mm ~ log_prob_occurence_weibull, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_weibull = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Predicted_Precipitation_24hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

```{r}
#hazen
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Greensboro_recurrence_24hr$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Greensboro_recurrence_24hr %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_24_mm ~ log_prob_occurence_hazen, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_hazen = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Predicted_Precipitation_24hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

```{r}
monthly_new_data_greensboro <- Greensboro_24hr_monthlyavg %>% 
  filter(Timeframe== '2000-2016' ) %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_24_mm),
            max=max(max_24_mm)) %>% 
  ungroup()

monthly_old_data_greensboro <- Greensboro_24hr_monthlyavg %>% 
  filter(Timeframe== '1980-1999' ) %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_24_mm),
            max=max(max_24_mm)) %>% 
  ungroup()
```

Greenville 24 hour events:

```{r}
#weibull
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Greenville_recurrence_24hr$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Greenville_recurrence_24hr %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_24_mm ~ log_prob_occurence_weibull, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_weibull = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Predicted_Precipitation_24hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

```{r}
#hazen
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Greenville_recurrence_24hr$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Greenville_recurrence_24hr %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_24_mm ~ log_prob_occurence_hazen, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_hazen = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Predicted_Precipitation_24hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

```{r}
monthly_new_data_Greenville <- Greenville_24hr_monthlyavg %>% 
  filter(Timeframe== '2000-2016' ) %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_24_mm),
            max=max(max_24_mm)) %>% 
  ungroup()

monthly_old_data_Greenville <- Greenville_24hr_monthlyavg %>% 
  filter(Timeframe== '1980-1999' ) %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_24_mm),
            max=max(max_24_mm)) %>% 
  ungroup()
```


# Boone 72hr storm events

Plot precipitation v likelihood of occurrence for the two time frames of interest (1980-1999 and 2000-2016)

```{r}
# Boone
Boone_72hr_plot_weibull <- Boone_72hr_recurrence %>%
  ggplot(aes(x = log_prob_occurence_weibull, 
             y = max_72hr_mm, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%) (Weibull)", 
       y = "Maximum 72-Hour Precipitation (mm)", 
       title = "Boone Monthly maximum 72-Hour Precipitation
       vs Probability of Occurrence (weibull)") +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_reverse(  # Keep the x-axis reversed
    labels = function(x) round(exp(x), 2)  # Convert log values back to probabilities for labels
  )

Boone_72hr_plot_weibull

```

Need to extract the precipitation depths for 10, 25, 50, and 100 year floods for each time period (for this 24 hour event). Fit a line of best fit to the probability distribution to interpolate for flood events that aren't observed.

```{r}
#weibull
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Boone_72hr_recurrence$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Boone_72hr_recurrence %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_72hr_mm ~ log_prob_occurence_weibull, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_weibull = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Boone_Predicted_Precipitation_72hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

Now we need to compare the monthly average from 2000-2016 maximum monthly 24-hr rain event. See which months exceed a 25 year flood from 1980-1999.

```{r}
boone_monthly_new_data_72 <- Boone_72hr_monthlyavg %>% 
  filter(Timeframe=='2000-2016') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_72hr_mm),
            max=max(max_72hr_mm)) %>% 
  ungroup()

boone_monthly_old_data_72 <-  Boone_72hr_monthlyavg %>% 
  filter(Timeframe=='1980-1999') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_72hr_mm),
            max=max(max_72hr_mm)) %>% 
  ungroup()
```

# Greensboro 72hr storm events

Plot precipitation v likelihood of occurrence for the two time frames of interest (1980-1999 and 2000-2016)

```{r}
# Greensboro
Greensboro_72hr_plot_weibull <- Greensboro_72hr_recurrence %>%
  ggplot(aes(x = log_prob_occurence_weibull, 
             y = max_72hr_mm, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%) (Weibull)", 
       y = "Maximum 72-Hour Precipitation (mm)", 
       title = "Greensboro Monthly maximum 72-Hour Precipitation
       vs Probability of Occurrence (weibull)") +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_reverse(  # Keep the x-axis reversed
    labels = function(x) round(exp(x), 2)  # Convert log values back to probabilities for labels
  )

Greensboro_72hr_plot_weibull

```

Need to extract the precipitation depths for 10, 25, 50, and 100 year floods for each time period (for this 24 hour event). Fit a line of best fit to the probability distribution to interpolate for flood events that aren't observed.

```{r}
#weibull
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Greensboro_72hr_recurrence$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Greensboro_72hr_recurrence %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_72hr_mm ~ log_prob_occurence_weibull, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_weibull = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Greensboro_Predicted_Precipitation_72hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

Now we need to compare the monthly average from 2000-2016 maximum monthly 24-hr rain event. See which months exceed a 25 year flood from 1980-1999.

```{r}
Greensboro_monthly_new_data_72 <- Greensboro_72hr_monthlyavg %>% 
  filter(Timeframe=='2000-2016') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_72hr_mm),
            max=max(max_72hr_mm)) %>% 
  ungroup()

Greensboro_monthly_old_data_72 <-  Greensboro_72hr_monthlyavg %>% 
  filter(Timeframe=='1980-1999') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_72hr_mm),
            max=max(max_72hr_mm)) %>% 
  ungroup()
```

# Greenville 72hr storm events

Plot precipitation v likelihood of occurrence for the two time frames of interest (1980-1999 and 2000-2016)

```{r}
# Greenville
Greenville_72hr_plot_weibull <- Greenville_72hr_recurrence %>%
  ggplot(aes(x = log_prob_occurence_weibull, 
             y = max_72hr_mm, 
             color = Timeframe)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Probability of Occurrence (%) (Weibull)", 
       y = "Maximum 72-Hour Precipitation (mm)", 
       title = "Greensboro Monthly maximum 72-Hour Precipitation
       vs Probability of Occurrence (weibull)") +
  theme_minimal() +
  scale_color_manual(values = c("thistle4", "tomato3"))+
  scale_x_reverse(  # Keep the x-axis reversed
    labels = function(x) round(exp(x), 2)  # Convert log values back to probabilities for labels
  )

Greenville_72hr_plot_weibull

```

Need to extract the precipitation depths for 10, 25, 50, and 100 year floods for each time period (for this 24 hour event). Fit a line of best fit to the probability distribution to interpolate for flood events that aren't observed.

```{r}
#weibull
# Define probabilities of occurrence
probabilities <- c(1, 2, 4, 10)

# Create an empty list to store results
results <- list()

# Step 1: Loop through each timeframe and fit models
for (tf in levels(Greenville_72hr_recurrence$Timeframe)) {
  
  # Filter data for the current timeframe
  data_subset <- Greenville_72hr_recurrence %>% 
    filter(Timeframe == tf)
  
  # Step 2: Fit a linear model
  model <- lm(max_72hr_mm ~ log_prob_occurence_weibull, data = data_subset)
  
  # Step 3: Create a new data frame for predictions
  new_data <- data.frame(log_prob_occurence_weibull = log(probabilities))
  
  # Step 4: Make predictions using the model
  predicted_precipitation <- predict(model, newdata = new_data)
  
  # Step 5: Combine the predictions with the corresponding probabilities and timeframe
  predicted_results <- data.frame(
    Probability = probabilities,
    Timeframe = tf,
    Greenville_Predicted_Precipitation_72hr_mm = predicted_precipitation
  )
  
  # Step 6: Store the results in the list
  results[[tf]] <- predicted_results
}

# Step 7: Combine all results into a single data frame
final_results <- bind_rows(results)

# Display the predicted precipitation for each timeframe
print(final_results)

```

Now we need to compare the monthly average from 2000-2016 maximum monthly 24-hr rain event. See which months exceed a 25 year flood from 1980-1999.

```{r}
Greenville_monthly_new_data_72 <- Greenville_72hr_monthlyavg %>% 
  filter(Timeframe=='2000-2016') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_72hr_mm),
            max=max(max_72hr_mm)) %>% 
  ungroup()

Greenville_monthly_old_data_72 <-  Greenville_72hr_monthlyavg %>% 
  filter(Timeframe=='1980-1999') %>% 
  group_by(month) %>% 
  summarise(avg=mean(max_72hr_mm),
            max=max(max_72hr_mm)) %>% 
  ungroup()
```

## Sources

Boone HUC 050500010201 Greensboro HUC 030300020105 Greenville 030201030403

## Annual data

Calculate sum of precipitation for each year in each city.

```{r, Calculate sum of precipitation for each year in each city}
Boone_annual_precip <- Boone_raw %>% 
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>% #remove NAs for Dec 31 in leap years
  group_by(year) %>% 
  summarise(Annual_precip_mm = sum(`Area Weighted Mean Precipitation (mm per day)`) ) %>% 
  mutate(Annual_precip_in = (`Annual_precip_mm`/25.4))

Greensboro_annual_precip <- Greensboro_raw %>% 
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>% #remove NAs for Dec 31 in leap years
  group_by(year) %>% 
  summarise(Annual_precip_mm = sum(`Area Weighted Mean Precipitation (mm per day)`) )%>% 
  mutate(Annual_precip_in = (`Annual_precip_mm`/25.4))

Greenville_annual_precip <- Greenville_raw %>% 
  drop_na(`Area Weighted Mean Precipitation (mm per day)`) %>% #remove NAs for Dec 31 in leap years
  group_by(year) %>% 
  summarise(Annual_precip_mm = sum(`Area Weighted Mean Precipitation (mm per day)`) )%>% 
  mutate(Annual_precip_in = (`Annual_precip_mm`/25.4))
```

rank the yearly total precipitation from highest to lowest

```{r, rank the yearly total precipitation from highest to lowest }
#looking at all of the data
Boone_annual_sorted <- Boone_annual_precip %>% 
  arrange(desc(Annual_precip_in))
Boone_annual_sorted$Rank = rank(-Boone_annual_sorted$Annual_precip_in)

#pre-2001
Boone_annual_sorted_old <- Boone_annual_precip[1:21,]%>% 
  arrange(desc(Annual_precip_in))
Boone_annual_sorted_old$Rank = rank(-Boone_annual_sorted_old$Annual_precip_in)

#post-2001
Boone_annual_sorted_new <- Boone_annual_precip[22:37,]%>% 
  arrange(desc(Annual_precip_in))
Boone_annual_sorted_new$Rank = rank(-Boone_annual_sorted_new$Annual_precip_in)                                              


Greensboro_annual_sorted <- Greensboro_annual_precip %>% 
  arrange(desc(Annual_precip_in))
Greensboro_annual_sorted$Rank = rank(-Greensboro_annual_sorted$Annual_precip_in)

Greenville_annual_sorted <- Greenville_annual_precip %>% 
  arrange(desc(Annual_precip_in))
Greenville_annual_sorted$Rank = rank(-Greenville_annual_sorted$Annual_precip_in)

```

Calculate probabilities and return periods for pre-2000 and post-2000

```{r}
n_all = 37 #number of events
Boone_annual_sorted <- Boone_annual_sorted %>% 
  mutate(weibull_return = (n_all+1)/Rank) %>% 
  mutate(hazen_return = 100/(100*(2*Rank-1)/(2*n_all)))

n_old = 21
Boone_annual_sorted_old <- Boone_annual_sorted_old %>% 
  mutate(weibull_return = (n_old+1)/Rank) %>% 
  mutate(hazen_return = 100/(100*(2*Rank-1)/(2*n_old)))

n_new= 16
Boone_annual_sorted_new <- Boone_annual_sorted_new %>% 
  mutate(weibull_return = (n_new+1)/Rank) %>% 
  mutate(hazen_return = 100/(100*(2*Rank-1)/(2*n_new)))

```

```{r}
boone_annual_plot<- 
  ggplot((Boone_annual_sorted),
         #choosing variables
         aes(
           y = Annual_precip_in,
           x = weibull_return
         )) +
  geom_point()+
  ggtitle("Precip v Return interval")+
  labs(y= "Precipitation (in)", x= "Return period (weibull)")
boone_annual_plot

boone_new_old <- ggplot() +
  geom_point(data=Boone_annual_sorted_new, aes(y=Annual_precip_in, x=weibull_return), color = 'tomato')+
  geom_point(data=Boone_annual_sorted_old, aes(y=Annual_precip_in, x=weibull_return), color = 'purple')+
  labs(y= "Precipitation (in)", x= "Return period (weibull)")

boone_new_old
```

#look at later: Find max storm events for each year

```{r}
Boone_max_storms <- Boone_rolling_sum %>%
  group_by(year) %>%
  summarise(
    max_24hr = max(`Area Weighted Mean Precipitation (mm per day)`, na.rm = TRUE),
    max_48hr = max(rolling_48hr, na.rm = TRUE),
    max_72hr = max(rolling_72hr, na.rm = TRUE)
  )

Greensboro_max_storms <- Greensboro_rolling_sum %>%
  group_by(year) %>%
  summarise(
    max_24hr = max(`Area Weighted Mean Precipitation (mm per day)`, na.rm = TRUE),
    max_48hr = max(rolling_48hr, na.rm = TRUE),
    max_72hr = max(rolling_72hr, na.rm = TRUE)
  )

Greenville_max_storms <- Greenville_rolling_sum %>%
  group_by(year) %>%
  summarise(
    max_24hr = max(`Area Weighted Mean Precipitation (mm per day)`, na.rm = TRUE),
    max_48hr = max(rolling_48hr, na.rm = TRUE),
    max_72hr = max(rolling_72hr, na.rm = TRUE)
  )
```

calculate reccurence intervals based on max rate

```{r}
# Step 4: Rank and calculate recurrence intervals for old period
n_old = nrow(Boone_old)
Boone_old <- Boone_old %>%
  arrange(desc(max_24hr)) %>%
  mutate(Rank_24hr = rank(-max_24hr),
         weibull_return_24hr = (n_old + 1) / Rank_24hr,
         hazen_return_24hr = (n_old + 0.5) / Rank_24hr) %>%
  arrange(desc(max_48hr)) %>%
  mutate(Rank_48hr = rank(-max_48hr),
         weibull_return_48hr = (n_old + 1) / Rank_48hr,
         hazen_return_48hr = (n_old + 0.5) / Rank_48hr) %>%
  arrange(desc(max_72hr)) %>%
  mutate(Rank_72hr = rank(-max_72hr),
         weibull_return_72hr = (n_old + 1) / Rank_72hr,
         hazen_return_72hr = (n_old + 0.5) / Rank_72hr)

# Step 4: Rank and calculate recurrence intervals for new period
n_new = nrow(Boone_new)
Boone_new <- Boone_new %>%
  arrange(desc(max_24hr)) %>%
  mutate(Rank_24hr = rank(-max_24hr),
         weibull_return_24hr = (n_new + 1) / Rank_24hr,
         hazen_return_24hr = (n_new + 0.5) / Rank_24hr) %>%
  arrange(desc(max_48hr)) %>%
  mutate(Rank_48hr = rank(-max_48hr),
         weibull_return_48hr = (n_new + 1) / Rank_48hr,
         hazen_return_48hr = (n_new + 0.5) / Rank_48hr) %>%
  arrange(desc(max_72hr)) %>%
  mutate(Rank_72hr = rank(-max_72hr),
         weibull_return_72hr = (n_new + 1) / Rank_72hr,
         hazen_return_72hr = (n_new + 0.5) / Rank_72hr)

```

Want to eliminate the each days data is independent of another day, so can implement an moving average. To determine how long to average across, we sort for the 50 largest precipitation events and see how long the last approximately.

```{r, looking at largest storm events}
# Boone 
Boone_sorted <- Boone_raw %>% 
  arrange(desc(`Area Weighted Mean Precipitation (mm per day)`))
Boone_top_50 <- Boone_sorted[1:50, ]

# Greensboro
Greensboro_sorted <- Greensboro_raw %>% 
  arrange(desc(`Area Weighted Mean Precipitation (mm per day)`))
Greensboro_top_50 <- Greensboro_sorted[1:50, ]

# Greenville
Greenville_sorted <- Greenville_raw %>% 
  arrange(desc(`Area Weighted Mean Precipitation (mm per day)`))
Greenville_top_50 <- Greenville_sorted[1:50, ]

```

Can look for a window of 7 days around a large precipitation event, how many days was precipitation above a minimum value of 4 mm?

```{r, checking length of longest rainfall events}
# Function to check rainfall duration for each large event
get_rain_duration <- function(data, date, window = 7) {
  # Find the index of the current date
  index <- which(data$Date == date)
  
  start_index <- max(1, index - window)  # Ensure we don't go out of bounds
  end_index <- min(nrow(data), index + window)  # Ensure we don't exceed the last row
  
  # Precipitation values in the 10 days before and after the event
  precip_values <- 
    data$`Area Weighted Mean Precipitation (mm per day)`[start_index:end_index]
  
  # Event day is the center, which is at index
  event_day_precip <- 
    data$`Area Weighted Mean Precipitation (mm per day)`[index]
  
  # Identify how long the event lasted (precipitation > 0)
  event_duration <- sum(precip_values > 4)
  
  return(event_duration)
}

# Apply the function for each of the top 50 values for each city 
Boone_durations <- sapply(1:nrow(Boone_top_50), function(i) {
  date <- Boone_top_50$Date[i]  # Get the date of the top 50th event
  get_rain_duration(Boone_raw, date)  # Calculate the rain duration for that event
})
Greensboro_durations <- sapply(1:nrow(Greensboro_top_50), function(i) {
  date <- Greensboro_top_50$Date[i]  # Get the date of the top 50th event
  get_rain_duration(Greensboro_raw, date)  # Calculate the rain duration for that event
})
Greenville_durations <- sapply(1:nrow(Greenville_top_50), function(i) {
  date <- Greenville_top_50$Date[i]  # Get the date of the top 50th event
  get_rain_duration(Greenville_raw, date)  # Calculate the rain duration for that event
})

# Add durations back to the top_50 dataframe
Boone_top_50$rain_event_duration <- Boone_durations
Greensboro_top_50$rain_event_duration <- Greensboro_durations
Greenville_top_50$rain_event_duration <- Greenville_durations

# Step 4: Calculate and print the average duration
Boone_average_duration <- mean(Boone_top_50$rain_event_duration)
print(paste("The average duration of the top 50 storm events in Boone is", Boone_average_duration, "days"))

Greenville_average_duration <- mean(Greenville_top_50$rain_event_duration)
print(paste("The average duration of the top 50 storm events in Greenville is", Greenville_average_duration, "days"))

Greensboro_average_duration <- mean(Greensboro_top_50$rain_event_duration)
print(paste("The average duration of the top 50 storm events in Greensboro is",Greensboro_average_duration, "days"))

```

Each rain event lasts approximately 2-3 days, so will implement a 3 day moving average across all of the datasets.

seperate into two timesteps, pre-2001 and post-2001

```{r}
# Boone_old <- Boone_max_storms %>% filter(year <= 2000)
# Boone_new <- Boone_max_storms %>% filter(year > 2000 & year <= 2016)
# 
# Greensboro_old <- Greensboro_max_storms %>% filter(year <= 2000)
# Greensboro_new <- Greensboro_max_storms %>% filter(year > 2000 & year <= 2016)
# 
# Greenville_old <- Greenville_max_storms %>% filter(year <= 2000)
# Greenville_new <- Greenville_max_storms %>% filter(year > 2000 & year <= 2016)
```
